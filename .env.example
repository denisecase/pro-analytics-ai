# ==========================================================
# .env.example
# ==========================================================
# This file sets environment variables for the application.
# Copy this file to .env and update values as needed.
#
# IMPORTANT: Make sure .env is listed in .gitignore
# to avoid accidentally committing secrets to version control.
#
# These variables are used by backend/utils/config.py
# ==========================================================

# Environment name: dev (local), test, prod (Lambda, etc.)
ENV=dev

# ==========================================================
# Large Language Model (LLM) Selection
# ==========================================================

# Choose how the model is loaded:
# Options:
# - none  → use API calls (OpenAI or OpenRouter)
# - 8bit  → load local 8-bit quantized model
# - 4bit  → load local 4-bit quantized model
QUANT_MODE=none

# If QUANT_MODE = none:
# - Specify LLM Provider: openai OR openrouter

LLM_PROVIDER=openrouter

# Required if using OpenRouter (free LLM gateway)
# Get a key from: https://openrouter.ai/account
OPENROUTER_API_KEY=or-your-openrouter-api-key-here

# Required if using OpenAI (paid, commercial)
# Get a key from: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model name for hosted API calls (used with both OpenAI and OpenRouter)
OPENAI_MODEL=gpt-3.5-turbo

# ==========================================================
# Local Model Setup (if QUANT_MODE = "8bit" or "4bit")
# ==========================================================

# Name of the local model to load from HuggingFace
# Example: TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ
MODEL_NAME=TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ

# ==========================================================
# Embedding Setup
# ==========================================================

# Embedding model used to convert text chunks to vectors
# Recommended: all-MiniLM-L6-v2 (fast, small, good quality)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Name of the vector database to use for storing embeddings
# Options: chroma (default), pinecone, weaviate
VECTOR_DB=chroma
